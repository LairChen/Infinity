from os import getenv
from typing import Union, Tuple, List, Dict

import gradio as gr
from fastapi import FastAPI

from utils import *


def init_language_model() -> Union[ChatModel, CompletionModel]:
    """åˆå§‹åŒ–æ¨¡å‹å’Œè¯è¡¨"""
    with open(file="{}/model_type.txt".format(path_eval_finetune), mode="r", encoding="utf-8") as f:
        my_model_name = f.read().strip()
    if CHAT_MODEL_TYPE.get(my_model_name, None) is not None:
        my_model = CHAT_MODEL_TYPE[my_model_name](name=my_model_name, path=path_eval_finetune)
    elif COMPLETION_MODEL_TYPE.get(my_model_name, None) is not None:
        my_model = COMPLETION_MODEL_TYPE[my_model_name](name=my_model_name, path=path_eval_finetune)
    else:
        raise FileNotFoundError("no existing language model")
    return my_model


model = init_language_model()


def submit(chatbot: List[List[str]], textbox: str, history: List[Dict[str, str]]) -> Tuple[List[List[str]], str]:  # noqa
    """æ¨¡å‹å›ç­”å¹¶æ›´æ–°èŠå¤©çª—å£"""
    history.append({"role": "user", "content": textbox})
    answer = model.generate(conversation=history)  # å¤šè½®å¯¹è¯ï¼Œéæµå¼æ–‡æœ¬è¾“å‡º
    history.append({"role": "assistant", "content": answer})
    chatbot.append([textbox, answer])
    return chatbot, ""


def clean(chatbot: List[List[str]], history: List[Dict[str, str]]) -> List[List[str]]:  # noqa
    """æ¸…ç†äººæœºå¯¹è¯å†å²è®°å½•"""
    chatbot.clear()
    history.clear()
    return chatbot


def init_demo() -> gr.Blocks:
    """åˆ›å»ºé¡µé¢æœåŠ¡"""
    with gr.Blocks(title="Infinity Model") as my_demo:
        # å¸ƒå±€åŒº
        gr.Markdown(value="<p align='center'>"
                          "<img src='https://openi.pcl.ac.cn/rhys2985/Infinity/raw/branch/master/templates/Infinity.png' "
                          "style='height: 100px'>"
                          "</p>")
        gr.Markdown(value="<center><font size=8>Infinity Large Language Model</center>")
        gr.Markdown(value="<center><font size=4>ğŸ˜¸ This Web UI is based on Infinity Model, developed by Rhys. ğŸ˜¸</center>")
        gr.Markdown(value="<center><font size=4>ğŸ”¥ <a href='https://openi.pcl.ac.cn/rhys2985/Infinity'>é¡¹ç›®åœ°å€</a> ğŸ”¥</center>")
        with gr.Row():
            with gr.Column(scale=1):
                pass
            with gr.Column(scale=5):
                chatbot = gr.Chatbot(label="Infinity Model")  # noqa
                textbox = gr.Textbox(label="Input", lines=2)
                history = gr.State(value=[])
                with gr.Row():
                    btnSubmit = gr.Button("Submit ğŸš€")
                    btnClean = gr.Button("Clean ğŸ§¹")
            with gr.Column(scale=1):
                pass
        gr.Markdown(value="<center><font size=4>âš  I strongly advise you not to knowingly generate or spread harmful content, "
                          "including rumor, hatred, violence, reactionary, pornography, deception, etc. âš </center>")
        # åŠŸèƒ½åŒº
        btnSubmit.click(fn=submit, inputs=[chatbot, textbox, history], outputs=[chatbot, textbox])
        btnClean.click(fn=clean, inputs=[chatbot, history], outputs=[chatbot])
    return my_demo


# AIåä½œå¹³å°ä¸é€‚ç”¨mainç©ºé—´æ‰§è¡Œï¼Œéœ€è¦ç”¨FastAPIæŒ‚è½½
demo = init_demo()
# æ­£å¼ç¯å¢ƒå¯åŠ¨æ–¹æ³•
if __name__ == "__main__":
    demo.launch()
# AIåä½œå¹³å°å¯åŠ¨æ–¹æ³•
else:
    app = gr.mount_gradio_app(app=FastAPI(), blocks=demo, path=getenv("OPENI_GRADIO_URL"))  # noqa
