from os import getenv
from typing import List, Tuple, Dict

import gradio as gr
import torch
from fastapi import FastAPI
from transformers import AutoModelForCausalLM, AutoTokenizer, PreTrainedModel, PreTrainedTokenizer


def init_model_and_tokenizer() -> Tuple[PreTrainedModel, PreTrainedTokenizer]:
    """åˆå§‹åŒ–æ¨¡å‹å’Œè¯è¡¨"""
    model = AutoModelForCausalLM.from_pretrained(
        pretrained_model_name_or_path="/pretrainmodel",
        torch_dtype=torch.float16,
        device_map="auto",
        trust_remote_code=True
    ).eval()
    tokenizer = AutoTokenizer.from_pretrained(
        pretrained_model_name_or_path="/pretrainmodel",
        use_fast=False,
        trust_remote_code=True
    )
    return model, tokenizer


def chat_with_model(history: List[str], content: str) -> List[Tuple[str, str]]:  # noqa
    """æ¨¡å‹å›ç­”å¹¶æ›´æ–°èŠå¤©çª—å£"""
    response = my_model.chat(my_tokenizer, [{"role": "user", "content": content}])
    if torch.backends.mps.is_available():  # noqa
        torch.mps.empty_cache()  # noqa
    return [(content, response)]


def reset_user_input() -> Dict:
    """æ¸…ç†ç”¨æˆ·è¾“å…¥ç©ºé—´"""
    return gr.update(value="")


# AIåä½œå¹³å°è‡ªæœ‰FastAPIæœåŠ¡ï¼Œè¿™é‡Œæ¨¡å—å¼è¿è¡ŒGradioæœåŠ¡å¹¶æŒ‚è½½ï¼Œæ•…ä¸é€‚ç”¨mainç©ºé—´æ‰§è¡Œ
my_model, my_tokenizer = init_model_and_tokenizer()
app = FastAPI()
with gr.Blocks(title="Infinity Model") as demo:
    gr.Markdown(value="<p align='center'><img src='https://openi.pcl.ac.cn/rhys2985/Infinity/raw/branch/master/Infinity.png' "
                      "style='height: 100px'/><p>")
    gr.Markdown(value="<center><font size=8>Infinity Chat Bot</center>")
    gr.Markdown(value="<center><font size=4>ğŸ˜¸ This Web UI is based on Infinity Model, developed by Rhys. ğŸ˜¸</center>")
    gr.Markdown(value="<center><font size=4>ğŸ”¥ <a href='https://openi.pcl.ac.cn/rhys2985/Infinity'>é¡¹ç›®åœ°å€</a> ğŸ”¥")
    chatbot = gr.Chatbot(label="Infinity Model")  # noqa
    textbox = gr.Textbox(label="Input", lines=2)
    with gr.Row():
        button = gr.Button("ğŸ‘‰ Submit ğŸ‘ˆ")
    button.click(fn=chat_with_model, inputs=[chatbot, textbox], outputs=[chatbot])
    button.click(fn=reset_user_input, inputs=[], outputs=[textbox])
    gr.Markdown(value="<font size=4>âš  I strongly advise you not to knowingly generate or spread harmful content, "
                      "including rumor, hatred, violence, reactionary, pornography, deception, etc. âš ")
app = gr.mount_gradio_app(app=app, blocks=demo, path=getenv("OPENI_GRADIO_URL"))  # noqa
