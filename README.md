![](https://openi.pcl.ac.cn/rhys2985/Infinity/raw/branch/master/templates/Infinity.png)

# Infinity

### Introduction

Infinity has contributed a platform to integrate the generation capability of large language models with your real-world business data, including finance, taxation and customer service, etc.

With Infinity, you can train models to connect to your downstream jobs, and provide corresponding service.

### Available Devices

* Nvidia GPU
* Ascend NPU

### Supported Models

* Baichuan2-7B-Chat
* Baichuan2-13B-Chat
* bce-embedding-base-v1
* chinese-ocr-db-crnn-server
* CodeFuse-DeepSeek-33B-4bits
* deepseek-coder-1.3b-instruct
* deepseek-coder-6.7b-instruct
* deepseek-coder-33B-instruct-GPTQ
* internlm2-chat-7b
* m3e-base
* m3e-small
* m3e-large
* pyramidbox-face-detection
* stable-diffusion
* Qwen-1.8B
* Qwen-7B
* Qwen-14B
* SUS-Chat-34B-GPTQ

### Work Stations

**debug mode**: Schedule daily task to obtain computing power points.

**train mode**: Based on your own business data, tune and save the large language model.

**infer mode**: Use FastAPI and Gradio to offer an online prediction stage.

***

I strongly advise you not to knowingly generate or spread harmful content, including rumor, hatred, violence, reactionary, pornography, deception, etc.
